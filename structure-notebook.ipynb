{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120691,"databundleVersionId":14435208,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Reading train and test dataset in pandaas**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntrain = pd.read_csv(\"/kaggle/input/mlp-term-3-2025-kaggle-assignment-2/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/mlp-term-3-2025-kaggle-assignment-2/test.csv\")\nsample_sub = pd.read_csv(\"/kaggle/input/mlp-term-3-2025-kaggle-assignment-2/sample_submission.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['arrival'] = pd.to_datetime(train['arrival'], errors='coerce')\ntest['arrival']  = pd.to_datetime(test['arrival'], errors='coerce')\n\nmedian_arr = train['arrival'].median()\n\ntrain['arrival'] = train['arrival'].fillna(median_arr)\ntest['arrival']  = test['arrival'].fillna(median_arr)\n\ntrain['arrival_year'] = train['arrival'].dt.year\ntrain['arrival_month'] = train['arrival'].dt.month\ntrain['arrival_day'] = train['arrival'].dt.day\n\ntest['arrival_year'] = test['arrival'].dt.year\ntest['arrival_month'] = test['arrival'].dt.month\ntest['arrival_day'] = test['arrival'].dt.day\n\ntrain.drop('arrival', axis=1, inplace=True)\ntest.drop('arrival', axis=1, inplace=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nnum_cols = ['id','adults','children','weekends','weekdays','lead_time','repeat',\n            'price','requests','arrival_year','arrival_month','arrival_day']\ncat_cols = ['meal_type','room_type','segment']\n\nnum_imputer = SimpleImputer(strategy=\"median\")\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\n\ntrain[num_cols] = num_imputer.fit_transform(train[num_cols])\ntest[num_cols]  = num_imputer.transform(test[num_cols])\n\ntrain[cat_cols] = cat_imputer.fit_transform(train[cat_cols])\ntest[cat_cols]  = cat_imputer.transform(test[cat_cols])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['total_days'] = train['weekdays'] + train['weekends']\ntest['total_days']  = test['weekdays'] + test['weekends']\n\ntrain['total_people'] = train['adults'] + train['children']\ntest['total_people']  = test['adults'] + test['children']\n\ntrain['price_per_person'] = train['price'] / (train['total_people'] + 1)\ntest['price_per_person']  = test['price'] / (test['total_people'] + 1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.get_dummies(train, columns=['meal_type','room_type','segment'], drop_first=True)\ntest  = pd.get_dummies(test,  columns=['meal_type','room_type','segment'], drop_first=True)\n\ntrain, test = train.align(test, join=\"left\", axis=1)\ntest['booking_status'] = 0\ntest = test.drop('booking_status', axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1 — Booking Status Count\nsns.countplot(x=train['booking_status'])\nplt.title(\"Booking Status Distribution\")\nplt.show()\n\n# 2 — Price Distribution\nsns.histplot(train['price'], kde=True)\nplt.title(\"Price Distribution\")\nplt.show()\n\n# 3 — Correlation Heatmap\nplt.figure(figsize=(12,6))\nsns.heatmap(train.corr(), cmap='coolwarm')\nplt.title(\"Correlation Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = train.drop(\"booking_status\", axis=1)\ny = train[\"booking_status\"]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score\n\nmodels = {\n    \"Logistic\": LogisticRegression(max_iter=500),\n    \"RF\": RandomForestClassifier(),\n    \"GB\": GradientBoostingClassifier(),\n    \"Ada\": AdaBoostClassifier(),\n    \"KNN\": KNeighborsClassifier(),\n    \"XGB\": XGBClassifier(eval_metric='logloss'),\n    \"LGBM\": LGBMClassifier()\n}\n\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_val)\n    print(name, accuracy_score(y_val, preds))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nrf_params = {\n    'n_estimators':[300,400,500],\n    'max_depth':[8,10,12,None],\n    'min_samples_split':[2,4],\n    'min_samples_leaf':[1,2]\n}\n\nrf_tune = RandomizedSearchCV(\n    RandomForestClassifier(),\n    rf_params,\n    n_iter=10,\n    cv=3,\n    scoring='accuracy',\n    n_jobs=-1,\n    random_state=42\n)\n\nrf_tune.fit(X_train, y_train)\nbest_rf = rf_tune.best_estimator_\nprint(\"RF Best Score:\", rf_tune.best_score_)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb_params = {\n    'n_estimators':[300,400],\n    'max_depth':[4,6],\n    'learning_rate':[0.03,0.05,0.1]\n}\n\nxgb_tune = RandomizedSearchCV(\n    XGBClassifier(eval_metric='logloss'),\n    xgb_params,\n    n_iter=6,\n    cv=3,\n    scoring='accuracy',\n    n_jobs=-1,\n    random_state=42\n)\n\nxgb_tune.fit(X_train, y_train)\nbest_xgb = xgb_tune.best_estimator_\nprint(\"XGB Best Score:\", xgb_tune.best_score_)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgb_params = {\n    'n_estimators':[200,300,400],\n    'max_depth':[4,6,8],\n    'learning_rate':[0.03,0.05,0.1]\n}\n\nlgb_tune = RandomizedSearchCV(\n    LGBMClassifier(),\n    lgb_params,\n    n_iter=6,\n    cv=3,\n    scoring='accuracy',\n    n_jobs=-1,\n    random_state=42\n)\n\nlgb_tune.fit(X_train, y_train)\nbest_lgb = lgb_tune.best_estimator_\nprint(\"LGBM Best Score:\", lgb_tune.best_score_)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare tuned scores\nscores = {\n    \"RF\": rf_tune.best_score_,\n    \"XGB\": xgb_tune.best_score_,\n    \"LGB\": lgb_tune.best_score_\n}\n\nprint(scores)\nbest_model_name = max(scores, key=scores.get)\nprint(\"Best Model:\", best_model_name)\n\nbest_model = {\"RF\":best_rf, \"XGB\":best_xgb, \"LGB\":best_lgb}[best_model_name]\n\n# Train on full data\nbest_model.fit(X, y)\n\n# Predict\ntest_preds = best_model.predict(test)\nsample_sub['booking_status'] = test_preds\nsample_sub.to_csv(\"submission.csv\", index=False)\n\nprint(\"submission.csv saved!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}